{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ds_cat_head_descr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "leCat = preprocessing.LabelEncoder()\n",
    "df['category_enc']=leCat.fit_transform(df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>head_descr</th>\n",
       "      <th>category_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>there were 2 mass shootings in teas last week,...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>hugh grant marries for the first time at age 5...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>jim carrey blasts 'castrato' adam schiff and d...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>julianna margulies uses donald trump poop bags...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>morgan freeman 'devastated' that seual harassm...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                         head_descr  \\\n",
       "0          CRIME  there were 2 mass shootings in teas last week,...   \n",
       "1  ENTERTAINMENT  hugh grant marries for the first time at age 5...   \n",
       "2  ENTERTAINMENT  jim carrey blasts 'castrato' adam schiff and d...   \n",
       "3  ENTERTAINMENT  julianna margulies uses donald trump poop bags...   \n",
       "4  ENTERTAINMENT  morgan freeman 'devastated' that seual harassm...   \n",
       "\n",
       "   category_enc  \n",
       "0             6  \n",
       "1            10  \n",
       "2            10  \n",
       "3            10  \n",
       "4            10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.head_descr, df.category_enc, test_size=0.20,\n",
    "                                                    random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119185,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119185, 70631)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119185, 70631)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "## Training Naive Bayes (NB) classifier on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
    "# The names â€˜vectâ€™ , â€˜tfidfâ€™ and â€˜clfâ€™ are arbitrary but will be used later.\n",
    "# We will be using the 'text_clf' going forward.\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy NB: 38.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       180\n",
      "           1       0.00      0.00      0.00       268\n",
      "           2       0.00      0.00      0.00       647\n",
      "           3       1.00      0.00      0.00       849\n",
      "           4       0.00      0.00      0.00       183\n",
      "           5       0.00      0.00      0.00       760\n",
      "           6       0.00      0.00      0.00       396\n",
      "           7       0.00      0.00      0.00       139\n",
      "           8       0.00      0.00      0.00       306\n",
      "           9       0.00      0.00      0.00       172\n",
      "          10       0.54      0.67      0.60      2415\n",
      "          11       0.00      0.00      0.00       115\n",
      "          12       0.00      0.00      0.00       177\n",
      "          13       0.68      0.24      0.36       851\n",
      "          14       0.00      0.00      0.00       183\n",
      "          15       0.00      0.00      0.00       342\n",
      "          16       1.00      0.00      0.00      1017\n",
      "          17       0.99      0.11      0.20       701\n",
      "          18       0.00      0.00      0.00       550\n",
      "          19       0.00      0.00      0.00       173\n",
      "          20       0.00      0.00      0.00       379\n",
      "          21       0.00      0.00      0.00       286\n",
      "          22       0.54      0.08      0.13      1320\n",
      "          23       1.00      0.02      0.04       676\n",
      "          24       0.32      0.99      0.48      5439\n",
      "          25       0.90      0.03      0.06       931\n",
      "          26       0.00      0.00      0.00       364\n",
      "          27       0.00      0.00      0.00       266\n",
      "          28       1.00      0.02      0.03       706\n",
      "          29       0.00      0.00      0.00       294\n",
      "          30       0.75      0.59      0.66      1418\n",
      "          31       0.00      0.00      0.00       373\n",
      "          32       1.00      0.00      0.01       355\n",
      "          33       0.00      0.00      0.00       484\n",
      "          34       0.74      0.53      0.62      1558\n",
      "          35       0.00      0.00      0.00       360\n",
      "          36       0.00      0.00      0.00       405\n",
      "          37       0.32      0.86      0.47      2565\n",
      "          38       1.00      0.01      0.03       573\n",
      "          39       0.00      0.00      0.00       382\n",
      "          40       0.00      0.00      0.00       239\n",
      "\n",
      "    accuracy                           0.38     29797\n",
      "   macro avg       0.29      0.10      0.09     29797\n",
      "weighted avg       0.44      0.38      0.27     29797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performance of NB Classifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "predicted = text_clf.predict(X_test)\n",
    "#print(np.mean(predicted == y_test))\n",
    "print(\"Accuracy NB: \"+str(round(accuracy_score(y_test, predicted),2)*100)+\"%\")\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Support Vector Machines - SVM and calculating its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, \n",
    "                                                   random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "#np.mean(predicted_svm == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM: 55.00000000000001%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.12      0.17       180\n",
      "           1       0.43      0.18      0.26       268\n",
      "           2       0.52      0.23      0.32       647\n",
      "           3       0.54      0.31      0.39       849\n",
      "           4       0.43      0.19      0.27       183\n",
      "           5       0.44      0.15      0.22       760\n",
      "           6       0.54      0.35      0.43       396\n",
      "           7       0.51      0.17      0.26       139\n",
      "           8       0.61      0.66      0.63       306\n",
      "           9       0.53      0.18      0.27       172\n",
      "          10       0.59      0.68      0.64      2415\n",
      "          11       0.28      0.10      0.14       115\n",
      "          12       0.33      0.10      0.16       177\n",
      "          13       0.57      0.65      0.61       851\n",
      "          14       0.20      0.09      0.13       183\n",
      "          15       0.37      0.14      0.20       342\n",
      "          16       0.38      0.11      0.17      1017\n",
      "          17       0.65      0.66      0.66       701\n",
      "          18       0.37      0.21      0.27       550\n",
      "          19       0.42      0.14      0.22       173\n",
      "          20       0.49      0.13      0.21       379\n",
      "          21       0.48      0.26      0.34       286\n",
      "          22       0.52      0.55      0.53      1320\n",
      "          23       0.43      0.15      0.22       676\n",
      "          24       0.54      0.93      0.68      5439\n",
      "          25       0.65      0.64      0.64       931\n",
      "          26       0.56      0.29      0.38       364\n",
      "          27       0.51      0.31      0.38       266\n",
      "          28       0.63      0.56      0.59       706\n",
      "          29       0.42      0.07      0.12       294\n",
      "          30       0.57      0.80      0.67      1418\n",
      "          31       0.36      0.09      0.15       373\n",
      "          32       0.57      0.31      0.40       355\n",
      "          33       0.52      0.20      0.29       484\n",
      "          34       0.63      0.81      0.71      1558\n",
      "          35       0.66      0.68      0.67       360\n",
      "          36       0.48      0.18      0.26       405\n",
      "          37       0.54      0.76      0.63      2565\n",
      "          38       0.43      0.19      0.26       573\n",
      "          39       0.49      0.15      0.23       382\n",
      "          40       0.42      0.19      0.26       239\n",
      "\n",
      "    accuracy                           0.55     29797\n",
      "   macro avg       0.49      0.33      0.37     29797\n",
      "weighted avg       0.53      0.55      0.50     29797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy SVM: \"+str(round(accuracy_score(y_test, predicted_svm),2)*100)+\"%\")\n",
    "print(classification_report(y_test, predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we are creating a list of parameters for which we would like to do performance tuning. \n",
    "# All the parameters name start with the classifier name (remember the arbitrary name we gave). \n",
    "# E.g. vect__ngram_range; here we are telling to use unigram and bigrams and choose the one which is optimal.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the best mean score and the params, run the following code\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "\n",
    "# Output for above should be: The accuracy has now increased to ~90.6% for the NB classifier (not so naive anymore! ðŸ˜„)\n",
    "# and the corresponding parameters are {â€˜clf__alphaâ€™: 0.01, â€˜tfidf__use_idfâ€™: True, â€˜vect__ngram_rangeâ€™: (1, 2)}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy CV clf: 56.00000000000001%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.14      0.21       180\n",
      "           1       0.54      0.16      0.24       268\n",
      "           2       0.51      0.28      0.36       647\n",
      "           3       0.49      0.37      0.42       849\n",
      "           4       0.57      0.17      0.27       183\n",
      "           5       0.54      0.30      0.38       760\n",
      "           6       0.54      0.52      0.53       396\n",
      "           7       0.56      0.17      0.26       139\n",
      "           8       0.68      0.42      0.52       306\n",
      "           9       0.43      0.14      0.21       172\n",
      "          10       0.60      0.73      0.66      2415\n",
      "          11       0.59      0.14      0.23       115\n",
      "          12       0.21      0.08      0.12       177\n",
      "          13       0.60      0.62      0.61       851\n",
      "          14       0.37      0.11      0.17       183\n",
      "          15       0.44      0.29      0.35       342\n",
      "          16       0.37      0.19      0.25      1017\n",
      "          17       0.84      0.66      0.74       701\n",
      "          18       0.36      0.30      0.32       550\n",
      "          19       0.70      0.13      0.22       173\n",
      "          20       0.61      0.23      0.34       379\n",
      "          21       0.51      0.34      0.41       286\n",
      "          22       0.41      0.56      0.47      1320\n",
      "          23       0.36      0.24      0.29       676\n",
      "          24       0.62      0.88      0.73      5439\n",
      "          25       0.69      0.50      0.58       931\n",
      "          26       0.64      0.27      0.38       364\n",
      "          27       0.67      0.29      0.41       266\n",
      "          28       0.75      0.56      0.64       706\n",
      "          29       0.54      0.18      0.27       294\n",
      "          30       0.74      0.78      0.76      1418\n",
      "          31       0.44      0.21      0.28       373\n",
      "          32       0.67      0.28      0.39       355\n",
      "          33       0.58      0.30      0.40       484\n",
      "          34       0.61      0.78      0.69      1558\n",
      "          35       0.74      0.49      0.59       360\n",
      "          36       0.50      0.21      0.29       405\n",
      "          37       0.44      0.81      0.57      2565\n",
      "          38       0.39      0.20      0.26       573\n",
      "          39       0.47      0.26      0.33       382\n",
      "          40       0.40      0.36      0.38       239\n",
      "\n",
      "    accuracy                           0.56     29797\n",
      "   macro avg       0.54      0.36      0.40     29797\n",
      "weighted avg       0.56      0.56      0.53     29797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_cv_clf = gs_clf.predict(X_test)\n",
    "print(\"Accuracy CV clf: \"+str(round(accuracy_score(y_test, predicted_cv_clf),2)*100)+\"%\")\n",
    "print(classification_report(y_test, predicted_cv_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarly doing grid search for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\WinPython\\python-3.7.6.amd64\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),\n",
    "                  'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy clf SVM: 56.00000000000001%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.13      0.19       180\n",
      "           1       0.58      0.18      0.28       268\n",
      "           2       0.56      0.27      0.36       647\n",
      "           3       0.52      0.31      0.39       849\n",
      "           4       0.46      0.17      0.25       183\n",
      "           5       0.57      0.17      0.26       760\n",
      "           6       0.54      0.40      0.46       396\n",
      "           7       0.91      0.14      0.25       139\n",
      "           8       0.67      0.67      0.67       306\n",
      "           9       0.51      0.21      0.30       172\n",
      "          10       0.63      0.70      0.66      2415\n",
      "          11       0.52      0.10      0.17       115\n",
      "          12       0.21      0.05      0.07       177\n",
      "          13       0.59      0.65      0.62       851\n",
      "          14       0.44      0.10      0.16       183\n",
      "          15       0.50      0.19      0.27       342\n",
      "          16       0.48      0.13      0.20      1017\n",
      "          17       0.67      0.74      0.71       701\n",
      "          18       0.43      0.21      0.28       550\n",
      "          19       0.57      0.12      0.20       173\n",
      "          20       0.56      0.14      0.23       379\n",
      "          21       0.54      0.29      0.38       286\n",
      "          22       0.51      0.60      0.55      1320\n",
      "          23       0.48      0.17      0.25       676\n",
      "          24       0.55      0.93      0.69      5439\n",
      "          25       0.69      0.64      0.66       931\n",
      "          26       0.55      0.30      0.39       364\n",
      "          27       0.62      0.31      0.41       266\n",
      "          28       0.67      0.58      0.62       706\n",
      "          29       0.54      0.06      0.12       294\n",
      "          30       0.57      0.82      0.67      1418\n",
      "          31       0.51      0.09      0.16       373\n",
      "          32       0.59      0.31      0.40       355\n",
      "          33       0.59      0.21      0.31       484\n",
      "          34       0.60      0.82      0.70      1558\n",
      "          35       0.67      0.69      0.68       360\n",
      "          36       0.53      0.17      0.25       405\n",
      "          37       0.51      0.81      0.62      2565\n",
      "          38       0.42      0.18      0.25       573\n",
      "          39       0.57      0.15      0.24       382\n",
      "          40       0.44      0.19      0.27       239\n",
      "\n",
      "    accuracy                           0.56     29797\n",
      "   macro avg       0.55      0.34      0.38     29797\n",
      "weighted avg       0.56      0.56      0.52     29797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_clf_svm = gs_clf_svm.predict(X_test)\n",
    "print(\"Accuracy clf SVM: \"+str(round(accuracy_score(y_test, predicted_clf_svm),2)*100)+\"%\")\n",
    "print(classification_report(y_test, predicted_clf_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.494345068295466"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming Code\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
    "                             ('mnb', MultinomialNB(fit_prior=False))])\n",
    "\n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(X_train, y_train)\n",
    "\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(X_test)\n",
    "\n",
    "np.mean(predicted_mnb_stemmed == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy MNB: 49.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       180\n",
      "           1       1.00      0.02      0.04       268\n",
      "           2       0.68      0.06      0.11       647\n",
      "           3       0.52      0.18      0.27       849\n",
      "           4       0.00      0.00      0.00       183\n",
      "           5       0.74      0.15      0.24       760\n",
      "           6       0.71      0.16      0.27       396\n",
      "           7       1.00      0.07      0.13       139\n",
      "           8       0.88      0.15      0.25       306\n",
      "           9       0.00      0.00      0.00       172\n",
      "          10       0.51      0.80      0.62      2415\n",
      "          11       0.00      0.00      0.00       115\n",
      "          12       0.00      0.00      0.00       177\n",
      "          13       0.59      0.63      0.61       851\n",
      "          14       1.00      0.01      0.02       183\n",
      "          15       0.45      0.04      0.07       342\n",
      "          16       0.81      0.07      0.12      1017\n",
      "          17       0.90      0.50      0.64       701\n",
      "          18       0.49      0.04      0.08       550\n",
      "          19       0.50      0.01      0.01       173\n",
      "          20       0.88      0.04      0.07       379\n",
      "          21       0.68      0.05      0.09       286\n",
      "          22       0.44      0.47      0.46      1320\n",
      "          23       0.70      0.07      0.12       676\n",
      "          24       0.47      0.96      0.63      5439\n",
      "          25       0.82      0.33      0.47       931\n",
      "          26       0.67      0.08      0.14       364\n",
      "          27       0.82      0.09      0.16       266\n",
      "          28       0.78      0.38      0.51       706\n",
      "          29       0.00      0.00      0.00       294\n",
      "          30       0.65      0.76      0.70      1418\n",
      "          31       0.67      0.02      0.03       373\n",
      "          32       0.79      0.12      0.21       355\n",
      "          33       0.59      0.10      0.16       484\n",
      "          34       0.58      0.78      0.67      1558\n",
      "          35       0.93      0.23      0.37       360\n",
      "          36       0.52      0.05      0.10       405\n",
      "          37       0.36      0.90      0.52      2565\n",
      "          38       0.72      0.05      0.09       573\n",
      "          39       0.60      0.04      0.07       382\n",
      "          40       0.60      0.01      0.02       239\n",
      "\n",
      "    accuracy                           0.49     29797\n",
      "   macro avg       0.59      0.20      0.22     29797\n",
      "weighted avg       0.57      0.49      0.41     29797\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\WinPython\\python-3.7.6.amd64\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy MNB: \"+str(round(accuracy_score(y_test, predicted_mnb_stemmed),2)*100)+\"%\")\n",
    "print(classification_report(y_test, predicted_mnb_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
